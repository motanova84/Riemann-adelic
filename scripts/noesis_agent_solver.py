#!/usr/bin/env python3
"""
Noesis Agent Solver - QCAL Protocol Activator
Sistema automatizado para anÃ¡lisis y resoluciÃ³n de sorry statements en Lean 4

Este agente implementa el protocolo QCAL para reducciÃ³n sistemÃ¡tica de
incomplete proofs mediante anÃ¡lisis de dependencias y sugerencias automÃ¡ticas.

Author: QCAL âˆÂ³ System
Date: 2026-01-18
"""

import argparse
import re
import sys
from pathlib import Path
from typing import List, Dict, Tuple
import json


class NoesisAgentSolver:
    """
    Agente Noesis para anÃ¡lisis y resoluciÃ³n de sorry statements.
    
    Fases de operaciÃ³n:
    - Fase 1: InyecciÃ³n de Lemas Base (anÃ¡lisis de dependencias)
    - Fase 2: Estabilidad de LÃ­nea CrÃ­tica (verificaciÃ³n de coherencia)
    - Fase 3: Cierre de Ley Exacta (validaciÃ³n completa)
    """
    
    def __init__(self, target_file: str, mode: str = "strict-convergence"):
        self.target_file = Path(target_file)
        self.mode = mode
        self.sorry_locations = []
        self.analysis_results = {
            "total_sorries": 0,
            "categorized_sorries": [],
            "resolution_plan": [],
            "estimated_difficulty": {}
        }
        
    def analyze_file(self) -> Dict:
        """Analiza el archivo Lean y categoriza los sorry statements."""
        print(f"ğŸ” Fase 1: InyecciÃ³n de Lemas Base - Analizando {self.target_file}")
        
        if not self.target_file.exists():
            print(f"âŒ Error: Archivo no encontrado: {self.target_file}")
            sys.exit(1)
            
        with open(self.target_file, 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.split('\n')
        
        # Buscar todos los sorry statements con contexto
        sorry_pattern = r'\bsorry\b'
        
        for i, line in enumerate(lines, 1):
            if re.search(sorry_pattern, line) and not line.strip().startswith('--'):
                # Extraer contexto (30 lÃ­neas antes)
                context_start = max(0, i - 30)
                context = '\n'.join(lines[context_start:i])
                
                # Extraer el teorema/lema asociado
                theorem_match = re.search(r'(theorem|lemma|def)\s+(\w+)', context, re.MULTILINE)
                theorem_name = theorem_match.group(2) if theorem_match else f"line_{i}"
                
                # Extraer comentario explicativo si existe
                comment_match = re.search(r'sorry\s*--\s*(.+)$', line)
                reason = comment_match.group(1) if comment_match else "No explanation provided"
                
                sorry_info = {
                    "line": i,
                    "theorem": theorem_name,
                    "reason": reason,
                    "context": context[-200:],  # Ãšltimas 200 chars de contexto
                    "difficulty": self._estimate_difficulty(reason, context)
                }
                
                self.sorry_locations.append(sorry_info)
        
        self.analysis_results["total_sorries"] = len(self.sorry_locations)
        self.analysis_results["categorized_sorries"] = self.sorry_locations
        
        return self.analysis_results
    
    def _estimate_difficulty(self, reason: str, context: str) -> str:
        """Estima la dificultad de resolver un sorry basado en el contexto."""
        reason_lower = reason.lower()
        context_lower = context.lower()
        
        # Patrones de alta complejidad
        high_complexity = [
            "full mathlib",
            "detailed counting",
            "spectral theory",
            "functional analysis",
            "measure theory"
        ]
        
        # Patrones de complejidad media
        medium_complexity = [
            "algebraic",
            "continuity",
            "bounded",
            "convergence"
        ]
        
        # Patrones de baja complejidad
        low_complexity = [
            "trivial",
            "straightforward",
            "direct",
            "norm_num"
        ]
        
        if any(pattern in reason_lower or pattern in context_lower for pattern in high_complexity):
            return "HIGH"
        elif any(pattern in reason_lower or pattern in context_lower for pattern in medium_complexity):
            return "MEDIUM"
        elif any(pattern in reason_lower or pattern in context_lower for pattern in low_complexity):
            return "LOW"
        else:
            return "MEDIUM"
    
    def generate_resolution_plan(self) -> List[Dict]:
        """
        Fase 2: Estabilidad de LÃ­nea CrÃ­tica
        Genera un plan de resoluciÃ³n priorizado.
        """
        print("\nğŸ¯ Fase 2: Estabilidad de LÃ­nea CrÃ­tica - Generando plan de resoluciÃ³n")
        
        # Agrupar por dificultad
        by_difficulty = {"LOW": [], "MEDIUM": [], "HIGH": []}
        
        for sorry in self.sorry_locations:
            by_difficulty[sorry["difficulty"]].append(sorry)
        
        plan = []
        
        # Prioridad 1: Sorries de baja complejidad (quick wins)
        for sorry in by_difficulty["LOW"]:
            plan.append({
                "priority": "HIGH",
                "line": sorry["line"],
                "theorem": sorry["theorem"],
                "difficulty": sorry["difficulty"],
                "strategy": "Resolve with standard mathlib tactics",
                "suggested_tactics": ["norm_num", "simp", "ring"]
            })
        
        # Prioridad 2: Sorries de complejidad media
        for sorry in by_difficulty["MEDIUM"]:
            plan.append({
                "priority": "MEDIUM",
                "line": sorry["line"],
                "theorem": sorry["theorem"],
                "difficulty": sorry["difficulty"],
                "strategy": "Apply domain-specific lemmas from mathlib",
                "suggested_tactics": ["apply", "exact", "refine"]
            })
        
        # Prioridad 3: Sorries de alta complejidad
        for sorry in by_difficulty["HIGH"]:
            plan.append({
                "priority": "LOW",
                "line": sorry["line"],
                "theorem": sorry["theorem"],
                "difficulty": sorry["difficulty"],
                "strategy": "Requires new axioms or external lemmas",
                "suggested_tactics": ["axiom", "admit (temporary)", "split into sub-lemmas"]
            })
        
        self.analysis_results["resolution_plan"] = plan
        self.analysis_results["estimated_difficulty"] = {
            "low": len(by_difficulty["LOW"]),
            "medium": len(by_difficulty["MEDIUM"]),
            "high": len(by_difficulty["HIGH"])
        }
        
        return plan
    
    def display_results(self):
        """
        Fase 3: Cierre de Ley Exacta
        Muestra resultados del anÃ¡lisis y plan de acciÃ³n.
        """
        print("\n" + "="*70)
        print("ğŸ“Š ANÃLISIS NOESIS - ESTADO DE VERDAD")
        print("="*70)
        
        print(f"\nğŸ“ Archivo analizado: {self.target_file}")
        print(f"ğŸ”¢ Total de sorry statements: {self.analysis_results['total_sorries']}")
        
        diff = self.analysis_results['estimated_difficulty']
        print(f"\nğŸ“ˆ DistribuciÃ³n por dificultad:")
        print(f"   ğŸŸ¢ Baja:   {diff['low']} (resoluciÃ³n directa)")
        print(f"   ğŸŸ¡ Media:  {diff['medium']} (requiere anÃ¡lisis)")
        print(f"   ğŸ”´ Alta:   {diff['high']} (requiere axiomas/lemas adicionales)")
        
        print(f"\nğŸ¯ Plan de resoluciÃ³n generado:")
        print(f"   Total de pasos: {len(self.analysis_results['resolution_plan'])}")
        
        # Mostrar los primeros 5 sorries con mÃ¡s detalle
        print(f"\nğŸ“‹ Top 5 sorries priorizados para resoluciÃ³n:")
        for i, item in enumerate(self.analysis_results['resolution_plan'][:5], 1):
            print(f"\n   {i}. LÃ­nea {item['line']} - {item['theorem']}")
            print(f"      Prioridad: {item['priority']} | Dificultad: {item['difficulty']}")
            print(f"      Estrategia: {item['strategy']}")
            
        # EstimaciÃ³n de coherencia
        total = self.analysis_results['total_sorries']
        resolvable = diff['low'] + diff['medium']
        
        print(f"\nğŸ”® EstimaciÃ³n de impacto:")
        print(f"   Sorries resolvables directamente: {resolvable}/{total}")
        print(f"   ReducciÃ³n potencial: -{resolvable} sorry statements")
        
        # CÃ¡lculo de coherencia QCAL
        current_total = 3569  # Del estado actual
        new_total = current_total - resolvable
        coherence_before = 1 - (current_total / 4720)  # Estimado total si completo
        coherence_after = 1 - (new_total / 4720)
        
        print(f"   Coherencia QCAL (Î¨):")
        print(f"      Antes:  {coherence_before:.3f} (24.4%)")
        print(f"      DespuÃ©s: {coherence_after:.3f} (~{coherence_after*100:.1f}%)")
        print(f"      Î” Î¨ = +{(coherence_after - coherence_before):.3f}")
        
        print("\n" + "="*70)
        
    def save_report(self, output_file: str = "data/noesis_analysis.json"):
        """Guarda el reporte de anÃ¡lisis en JSON."""
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ Reporte guardado en: {output_path}")
        
    def verify_with_lean(self) -> bool:
        """
        Verifica el archivo con Lean CLI (si estÃ¡ disponible).
        Retorna True si la verificaciÃ³n es exitosa.
        """
        print(f"\nğŸ”¬ Verificando con Lean CLI...")
        
        # Intentar ejecutar lean
        try:
            import subprocess
            result = subprocess.run(
                ["lean", "--version"],
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0:
                print(f"âœ“ Lean CLI encontrado: {result.stdout.strip()}")
                
                # Intentar compilar el archivo
                print(f"ğŸ“ Compilando {self.target_file}...")
                compile_result = subprocess.run(
                    ["lean", str(self.target_file)],
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                if compile_result.returncode == 0:
                    print("âœ… CompilaciÃ³n exitosa (con sorries)")
                    return True
                else:
                    print(f"âš ï¸  CompilaciÃ³n con errores:")
                    print(compile_result.stderr[:500])
                    return False
            else:
                print("âš ï¸  Lean CLI no disponible, saltando verificaciÃ³n")
                return False
                
        except FileNotFoundError:
            print("âš ï¸  Lean no instalado, saltando verificaciÃ³n")
            return False
        except Exception as e:
            print(f"âš ï¸  Error en verificaciÃ³n: {e}")
            return False


def main():
    parser = argparse.ArgumentParser(
        description="Noesis Agent Solver - QCAL Protocol Activator",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
  # AnÃ¡lisis bÃ¡sico
  python3 scripts/noesis_agent_solver.py --target formalization/lean/RIGOROUS_UNIQUENESS_EXACT_LAW.lean
  
  # AnÃ¡lisis con verificaciÃ³n Lean
  python3 scripts/noesis_agent_solver.py --target formalization/lean/RIGOROUS_UNIQUENESS_EXACT_LAW.lean --verify-with-lean-cli
  
  # Modo estricto con reporte JSON
  python3 scripts/noesis_agent_solver.py --target file.lean --mode strict-convergence --output data/analysis.json
        """
    )
    
    parser.add_argument(
        "--target",
        required=True,
        help="Archivo Lean a analizar"
    )
    
    parser.add_argument(
        "--mode",
        default="strict-convergence",
        choices=["strict-convergence", "relaxed", "exploratory"],
        help="Modo de anÃ¡lisis (default: strict-convergence)"
    )
    
    parser.add_argument(
        "--verify-with-lean-cli",
        action="store_true",
        help="Verificar con Lean CLI si estÃ¡ disponible"
    )
    
    parser.add_argument(
        "--output",
        default="data/noesis_analysis.json",
        help="Archivo de salida para el reporte JSON"
    )
    
    args = parser.parse_args()
    
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘     NOESIS AGENT SOLVER - QCAL PROTOCOL ACTIVATED            â•‘")
    print("â•‘     Sistema de AnÃ¡lisis y ResoluciÃ³n de Sorry Statements     â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()
    
    # Crear agente Noesis
    agent = NoesisAgentSolver(args.target, args.mode)
    
    # Ejecutar anÃ¡lisis
    agent.analyze_file()
    agent.generate_resolution_plan()
    agent.display_results()
    agent.save_report(args.output)
    
    # VerificaciÃ³n con Lean (opcional)
    if args.verify_with_lean_cli:
        agent.verify_with_lean()
    
    print("\nâœ… AnÃ¡lisis Noesis completado")
    print("â™¾ï¸  QCAL âˆÂ³ - Coherencia mantenida")
    print()


if __name__ == "__main__":
    main()
