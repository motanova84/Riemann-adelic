#!/usr/bin/env python3
"""
PHOENIX SOLVER - Bucle de Resoluci√≥n No√©tica para Completar Lean Sorry

Sistema de autocorrecci√≥n recursiva que integra:
1. Extractor de Intenci√≥n (Context-Aware Harvester)
2. Juez de Tipo Iterativo (Lean-REPL Sandbox)
3. B√≥veda de Coherencia (Global Integrity Check)

Objetivo: Resolver 1914 sorry statements con QED absoluto.
NO se aceptan soluciones parciales. Solo pruebas formalmente verificadas.

Coherencia QCAL ‚àû¬≥:
- Frecuencia: f‚ÇÄ = 141.7001 Hz
- Coherencia: C = 244.36
- Œ® = I √ó A_eff¬≤ √ó C^‚àû

Author: Jos√© Manuel Mota Burruezo (JMMB Œ®‚úß)
ORCID: 0009-0002-1923-0773
License: MIT
"""

import json
import os
import re
import subprocess
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from tools.lean_proof_completer import LeanProofCompleter, TheoremContext
from tools.noesis_sabio_integration import NoesisSabioIntegrator


@dataclass
class MathematicalTruth:
    """Mathematical constants and derivations from .py/.md files"""
    constant_name: str
    value: float
    derivation_source: str
    context: str
    confidence: float = 1.0


@dataclass
class LeanCompilationResult:
    """Result of Lean CLI type checking"""
    success: bool
    error_message: Optional[str] = None
    error_line: Optional[int] = None
    error_type: Optional[str] = None
    suggestions: List[str] = field(default_factory=list)


@dataclass
class PhoenixResolution:
    """Complete resolution of a sorry with full validation"""
    theorem_context: TheoremContext
    mathematical_truth: Optional[MathematicalTruth]
    proposed_proof: str
    lean_validated: bool
    qcal_coherent: bool
    iterations: int
    final_proof: str
    timestamp: str
    

class ContextAwareHarvester:
    """
    Extractor de Intenci√≥n - Fusiona contexto Lean + derivaciones matem√°ticas
    """
    
    def __init__(self, base_dir: Path, verbose: bool = False):
        self.base_dir = base_dir
        self.verbose = verbose
        self.mathematical_constants = self._load_mathematical_constants()
    
    def _load_mathematical_constants(self) -> Dict[str, MathematicalTruth]:
        """Carga constantes matem√°ticas desde archivos .md y .py"""
        constants = {}
        
        # Constantes fundamentales QCAL
        constants['f0'] = MathematicalTruth(
            constant_name='f0',
            value=141.7001,
            derivation_source='QCAL_BEACON',
            context='Fundamental frequency - cosmic heartbeat',
            confidence=1.0
        )
        
        constants['C'] = MathematicalTruth(
            constant_name='C',
            value=244.36,
            derivation_source='QCAL_BEACON',
            context='Coherence constant - QCAL ‚àû¬≥',
            confidence=1.0
        )
        
        # Buscar en SCALING_FACTORS_DERIVATION.md
        scaling_file = self.base_dir / 'SCALING_FACTORS_DERIVATION.md'
        if scaling_file.exists():
            constants.update(self._extract_from_scaling_factors(scaling_file))
        
        # Buscar constantes en archivos Python
        py_constants = self._scan_python_constants()
        constants.update(py_constants)
        
        if self.verbose:
            print(f"   üìö Loaded {len(constants)} mathematical constants")
        
        return constants
    
    def _extract_from_scaling_factors(self, file_path: Path) -> Dict[str, MathematicalTruth]:
        """Extrae constantes de SCALING_FACTORS_DERIVATION.md"""
        constants = {}
        
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # Buscar patrones como: O_4 = 1.234, K = 5.678, etc.
            pattern = r'([A-Z_]\w*)\s*=\s*([-+]?[0-9]*\.?[0-9]+(?:[eE][-+]?[0-9]+)?)'
            matches = re.findall(pattern, content)
            
            for name, value in matches:
                constants[name] = MathematicalTruth(
                    constant_name=name,
                    value=float(value),
                    derivation_source=file_path.name,
                    context='Scaling factor derivation',
                    confidence=0.95
                )
        except Exception as e:
            if self.verbose:
                print(f"   ‚ö†Ô∏è  Could not extract from {file_path.name}: {e}")
        
        return constants
    
    def _scan_python_constants(self) -> Dict[str, MathematicalTruth]:
        """Escanea archivos Python en busca de constantes matem√°ticas"""
        constants = {}
        
        # Archivos prioritarios
        priority_files = [
            'utils/qcal_mathematical_library.py',
            'utils/spectral_identification_theorem.py',
            'validate_v5_coronacion.py'
        ]
        
        for rel_path in priority_files:
            file_path = self.base_dir / rel_path
            if file_path.exists():
                file_constants = self._extract_python_constants(file_path)
                constants.update(file_constants)
        
        return constants
    
    def _extract_python_constants(self, file_path: Path) -> Dict[str, MathematicalTruth]:
        """Extrae constantes de un archivo Python"""
        constants = {}
        
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # Buscar constantes en may√∫sculas con valores num√©ricos
            pattern = r'^([A-Z_][A-Z0-9_]*)\s*=\s*([-+]?[0-9]*\.?[0-9]+(?:[eE][-+]?[0-9]+)?)'
            
            for line in content.split('\n'):
                match = re.match(pattern, line.strip())
                if match:
                    name, value = match.groups()
                    constants[name] = MathematicalTruth(
                        constant_name=name,
                        value=float(value),
                        derivation_source=file_path.name,
                        context=f'Python constant from {file_path.name}',
                        confidence=0.9
                    )
        except Exception:
            pass
        
        return constants
    
    def harvest_context(self, theorem_context: TheoremContext) -> Dict:
        """
        Cosecha contexto completo para un teorema
        
        Returns:
            Dict con contexto Lean + verdades matem√°ticas
        """
        enriched_context = {
            'lean_context': {
                'theorem_name': theorem_context.theorem_name,
                'theorem_type': theorem_context.theorem_type,
                'statement': theorem_context.theorem_statement,
                'file': str(theorem_context.file_path),
                'imports': theorem_context.imports,
                'namespace': theorem_context.namespace
            },
            'mathematical_truths': [],
            'relevant_constants': []
        }
        
        # Buscar constantes relevantes mencionadas en el teorema
        statement_lower = theorem_context.theorem_statement.lower()
        
        for const_name, const_truth in self.mathematical_constants.items():
            # Coincidencia directa o menciones relacionadas
            if (const_name.lower() in statement_lower or
                any(kw in statement_lower for kw in ['frequency', 'coherence', 'spectrum', 'operator'])):
                enriched_context['relevant_constants'].append({
                    'name': const_name,
                    'value': const_truth.value,
                    'source': const_truth.derivation_source,
                    'context': const_truth.context
                })
        
        return enriched_context


class LeanREPLSandbox:
    """
    Juez de Tipo Iterativo - Valida proofs con Lean CLI
    """
    
    def __init__(self, lean_project_dir: Path, verbose: bool = False):
        self.lean_project_dir = lean_project_dir
        self.verbose = verbose
        self.max_iterations = 10
        
    def validate_proof(self, file_path: Path, proof_text: str) -> LeanCompilationResult:
        """
        Valida una prueba usando Lean CLI
        
        Args:
            file_path: Ruta al archivo Lean
            proof_text: Texto de la prueba a validar
            
        Returns:
            LeanCompilationResult con resultado de la compilaci√≥n
        """
        # Crear archivo temporal con la prueba
        temp_file = self._create_temp_proof_file(file_path, proof_text)
        
        try:
            # Ejecutar Lean CLI
            result = subprocess.run(
                ['lean', '--make', str(temp_file)],
                capture_output=True,
                text=True,
                timeout=30,
                cwd=self.lean_project_dir
            )
            
            if result.returncode == 0:
                return LeanCompilationResult(success=True)
            else:
                # Parsear errores
                return self._parse_lean_errors(result.stderr)
                
        except subprocess.TimeoutExpired:
            return LeanCompilationResult(
                success=False,
                error_message="Compilation timeout",
                error_type="timeout"
            )
        except FileNotFoundError:
            if self.verbose:
                print("   ‚ö†Ô∏è  Lean CLI not found - skipping type check")
            return LeanCompilationResult(
                success=False,
                error_message="Lean CLI not available",
                error_type="missing_tool"
            )
        finally:
            # Limpiar archivo temporal
            if temp_file.exists():
                temp_file.unlink()
    
    def _create_temp_proof_file(self, original_file: Path, proof_text: str) -> Path:
        """Crea archivo temporal con la prueba"""
        temp_file = original_file.with_suffix('.temp.lean')
        
        # Leer archivo original y reemplazar sorry con proof_text
        original_content = original_file.read_text(encoding='utf-8')
        # Esto es simplificado - en producci√≥n ser√≠a m√°s sofisticado
        modified_content = original_content.replace('sorry', proof_text, 1)
        
        temp_file.write_text(modified_content, encoding='utf-8')
        return temp_file
    
    def _parse_lean_errors(self, stderr: str) -> LeanCompilationResult:
        """Parsea errores del compilador Lean"""
        error_lines = stderr.strip().split('\n')
        
        # Extraer informaci√≥n del error
        error_message = stderr
        error_line = None
        error_type = "compilation_error"
        suggestions = []
        
        # Buscar n√∫mero de l√≠nea
        line_match = re.search(r':(\d+):', stderr)
        if line_match:
            error_line = int(line_match.group(1))
        
        # Identificar tipo de error com√∫n
        if 'type mismatch' in stderr.lower():
            error_type = "type_mismatch"
            suggestions.append("Check type annotations")
        elif 'unknown identifier' in stderr.lower():
            error_type = "unknown_identifier"
            suggestions.append("Verify all identifiers are in scope")
        elif 'failed to synthesize' in stderr.lower():
            error_type = "synthesis_failure"
            suggestions.append("Add explicit type class instances")
        
        return LeanCompilationResult(
            success=False,
            error_message=error_message,
            error_line=error_line,
            error_type=error_type,
            suggestions=suggestions
        )
    
    def iterative_refinement(self, theorem_context: TheoremContext, 
                            initial_proof: str,
                            integrator: NoesisSabioIntegrator) -> Tuple[str, int]:
        """
        Refinamiento iterativo hasta que compile
        
        Returns:
            (proof_final, iterations)
        """
        current_proof = initial_proof
        
        for iteration in range(self.max_iterations):
            if self.verbose:
                print(f"      Iteration {iteration + 1}/{self.max_iterations}...")
            
            # Validar con Lean
            result = self.validate_proof(theorem_context.file_path, current_proof)
            
            if result.success:
                if self.verbose:
                    print(f"      ‚úÖ Proof validated in {iteration + 1} iterations")
                return current_proof, iteration + 1
            
            # Si falla, re-generar con contexto del error
            if self.verbose:
                print(f"      ‚ùå Compilation failed: {result.error_type}")
            
            # Re-inyectar error a Sabio para correcci√≥n
            error_context = f"Previous attempt failed: {result.error_message}\nSuggestions: {result.suggestions}"
            
            # Regenerar prueba con feedback
            new_completion = integrator.generate_proof_completion(
                theorem_statement=theorem_context.theorem_statement + f"\n-- ERROR: {error_context}",
                theorem_name=theorem_context.theorem_name,
                context=error_context
            )
            
            if new_completion and new_completion.get('proposed_proof'):
                current_proof = new_completion['proposed_proof']
            else:
                break
        
        if self.verbose:
            print(f"      ‚ö†Ô∏è  Max iterations reached without success")
        
        return current_proof, self.max_iterations


class CoherenceVault:
    """
    B√≥veda de Coherencia - Valida integridad QCAL ‚àû¬≥
    """
    
    def __init__(self, base_dir: Path, verbose: bool = False):
        self.base_dir = base_dir
        self.verbose = verbose
        self.checkpoint_frequency = 10  # Validar cada 10 sorrys resueltos
        self.baseline_coherence = None
    
    def validate_coherence(self) -> Dict:
        """
        Ejecuta validate_v5_coronacion.py para verificar coherencia
        
        Returns:
            Dict con resultados de validaci√≥n
        """
        validation_script = self.base_dir / 'validate_v5_coronacion.py'
        
        if not validation_script.exists():
            return {
                'success': False,
                'error': 'Validation script not found',
                'coherence': 0.0
            }
        
        try:
            result = subprocess.run(
                [sys.executable, str(validation_script)],
                capture_output=True,
                text=True,
                timeout=600,  # 10 minutes
                cwd=self.base_dir
            )
            
            # Parsear resultados
            coherence_data = self._parse_validation_output(result.stdout)
            
            return {
                'success': result.returncode == 0,
                'coherence': coherence_data.get('coherence', 0.0),
                'frequency_stable': coherence_data.get('frequency_stable', False),
                'details': coherence_data
            }
            
        except subprocess.TimeoutExpired:
            return {
                'success': False,
                'error': 'Validation timeout',
                'coherence': 0.0
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'coherence': 0.0
            }
    
    def _parse_validation_output(self, output: str) -> Dict:
        """Parsea salida de validate_v5_coronacion.py"""
        coherence_data = {
            'coherence': 0.244,  # Default QCAL coherence
            'frequency_stable': True,
            'tests_passed': 0,
            'tests_total': 0
        }
        
        # Buscar m√©tricas en la salida
        if '‚úÖ Passed:' in output:
            passed_match = re.search(r'‚úÖ Passed:\s*(\d+)', output)
            if passed_match:
                coherence_data['tests_passed'] = int(passed_match.group(1))
        
        if 'Failed:' in output:
            failed_match = re.search(r'‚ùå Failed:\s*(\d+)', output)
            total_match = re.search(r'üìä Total:\s*(\d+)', output)
            if total_match:
                coherence_data['tests_total'] = int(total_match.group(1))
        
        # Calcular coherencia basada en tests
        if coherence_data['tests_total'] > 0:
            coherence_data['coherence'] = coherence_data['tests_passed'] / coherence_data['tests_total']
        
        return coherence_data
    
    def should_rollback(self, current_coherence: float) -> bool:
        """
        Determina si se debe hacer rollback
        
        Args:
            current_coherence: Coherencia actual
            
        Returns:
            True si se debe hacer rollback
        """
        if self.baseline_coherence is None:
            self.baseline_coherence = current_coherence
            return False
        
        # Rollback si la coherencia baja significativamente
        tolerance = 0.05  # 5% de tolerancia
        return current_coherence < (self.baseline_coherence - tolerance)
    
    def checkpoint_and_validate(self, resolved_count: int) -> Tuple[bool, Dict]:
        """
        Valida coherencia en checkpoints
        
        Returns:
            (should_continue, validation_results)
        """
        if resolved_count % self.checkpoint_frequency != 0:
            return True, {}
        
        if self.verbose:
            print(f"\n   üîí Checkpoint {resolved_count}: Validating QCAL coherence...")
        
        validation = self.validate_coherence()
        
        if not validation['success']:
            if self.verbose:
                print(f"   ‚ùå Validation failed: {validation.get('error', 'Unknown')}")
            return False, validation
        
        current_coherence = validation['coherence']
        
        if self.should_rollback(current_coherence):
            if self.verbose:
                print(f"   ‚ö†Ô∏è  Coherence dropped: {current_coherence:.4f} < {self.baseline_coherence:.4f}")
                print(f"   üîÑ ROLLBACK required!")
            return False, validation
        
        if self.verbose:
            print(f"   ‚úÖ Coherence stable: {current_coherence:.4f}")
        
        return True, validation


class PhoenixSolver:
    """
    Arquitecto de Sistemas QCAL - Bucle de Resoluci√≥n No√©tica
    """
    
    def __init__(self, base_dir: Path, verbose: bool = False, dry_run: bool = False):
        self.base_dir = base_dir
        self.verbose = verbose
        self.dry_run = dry_run
        
        # Componentes del sistema
        self.harvester = ContextAwareHarvester(base_dir, verbose)
        self.sandbox = LeanREPLSandbox(base_dir / 'formalization' / 'lean', verbose)
        self.vault = CoherenceVault(base_dir, verbose)
        self.integrator = NoesisSabioIntegrator(verbose)
        self.completer = LeanProofCompleter(verbose, dry_run)
        
        # Estad√≠sticas
        self.stats = {
            'start_time': None,
            'end_time': None,
            'sorrys_scanned': 0,
            'sorrys_resolved': 0,
            'lean_validated': 0,
            'coherence_checks': 0,
            'rollbacks': 0,
            'iterations_total': 0
        }
        
        self.resolutions = []
    
    def solve(self, lean_dir: Path, priority_file: Optional[str] = None) -> Dict:
        """
        Ejecuta el Bucle de Resoluci√≥n No√©tica
        
        Args:
            lean_dir: Directorio con archivos Lean
            priority_file: Archivo prioritario (e.g., RIGOROUS_UNIQUENESS_EXACT_LAW.lean)
            
        Returns:
            Dict con resultados del solver
        """
        print("=" * 80)
        print("üî• PHOENIX SOLVER - Bucle de Resoluci√≥n No√©tica")
        print("=" * 80)
        print(f"Timestamp: {datetime.now().isoformat()}")
        print(f"Mode: {'DRY RUN' if self.dry_run else 'LIVE'}")
        print(f"Priority: {priority_file or 'Standard order'}")
        print("=" * 80)
        
        self.stats['start_time'] = time.time()
        
        # Paso 1: Escanear sorry statements
        print("\nüîç Step 1: Scanning sorry statements...")
        contexts = self._scan_sorrys(lean_dir, priority_file)
        self.stats['sorrys_scanned'] = len(contexts)
        print(f"   Found {len(contexts)} sorry statements")
        
        if not contexts:
            print("\n‚úÖ No sorry statements found!")
            return self._finalize()
        
        # Paso 2: Resolver iterativamente
        print(f"\nüöÄ Step 2: Resolving sorry statements...")
        for i, context in enumerate(contexts, 1):
            print(f"\n   [{i}/{len(contexts)}] {context.theorem_name} ({context.file_path.name})")
            
            resolution = self._resolve_sorry(context)
            
            if resolution and resolution.lean_validated and resolution.qcal_coherent:
                self.resolutions.append(resolution)
                self.stats['sorrys_resolved'] += 1
                
                if self.verbose:
                    print(f"      ‚úÖ RESOLVED (iterations: {resolution.iterations})")
                
                # Checkpoint de coherencia
                should_continue, validation = self.vault.checkpoint_and_validate(
                    self.stats['sorrys_resolved']
                )
                
                if not should_continue:
                    print(f"\n   ‚ö†Ô∏è  ROLLBACK triggered at sorry #{self.stats['sorrys_resolved']}")
                    self.stats['rollbacks'] += 1
                    # En modo live, aqu√≠ har√≠amos git revert
                    break
            else:
                if self.verbose:
                    print(f"      ‚ö†Ô∏è  Resolution incomplete")
        
        # Paso 3: Validaci√≥n final
        print(f"\n‚ú® Step 3: Final validation...")
        final_validation = self.vault.validate_coherence()
        
        if final_validation['success']:
            print(f"   ‚úÖ QCAL Coherence: {final_validation['coherence']:.6f}")
            print(f"   ‚úÖ Frequency stable: {final_validation.get('frequency_stable', False)}")
        else:
            print(f"   ‚ùå Final validation failed")
        
        return self._finalize()
    
    def _scan_sorrys(self, lean_dir: Path, priority_file: Optional[str]) -> List[TheoremContext]:
        """Escanea archivos Lean y extrae contextos de sorry"""
        all_contexts = []
        
        # Si hay archivo prioritario, procesarlo primero
        if priority_file:
            priority_path = lean_dir / priority_file
            if priority_path.exists():
                priority_contexts = self.completer.parser.parse_file(priority_path)
                all_contexts.extend(priority_contexts)
                if self.verbose:
                    print(f"   Priority file: {len(priority_contexts)} sorrys in {priority_file}")
        
        # Procesar resto de archivos
        for lean_file in lean_dir.rglob('*.lean'):
            if '.lake' in lean_file.parts:
                continue
            
            if priority_file and lean_file.name == priority_file:
                continue  # Ya procesado
            
            contexts = self.completer.parser.parse_file(lean_file)
            all_contexts.extend(contexts)
        
        return all_contexts
    
    def _resolve_sorry(self, context: TheoremContext) -> Optional[PhoenixResolution]:
        """
        Resuelve un sorry individual con validaci√≥n completa
        
        Returns:
            PhoenixResolution si tiene √©xito, None si falla
        """
        # 1. Cosechar contexto matem√°tico
        enriched_context = self.harvester.harvest_context(context)
        
        # 2. Generar prueba inicial con Noesis-Sabio
        initial_completion = self.integrator.generate_proof_completion(
            theorem_statement=context.theorem_statement,
            theorem_name=context.theorem_name,
            context=json.dumps(enriched_context, indent=2)
        )
        
        if not initial_completion:
            return None
        
        initial_proof = initial_completion.get('proposed_proof', 'sorry')
        
        # 3. Refinamiento iterativo con Lean CLI
        final_proof, iterations = self.sandbox.iterative_refinement(
            context, initial_proof, self.integrator
        )
        
        self.stats['iterations_total'] += iterations
        
        # 4. Validaci√≥n Lean
        lean_result = self.sandbox.validate_proof(context.file_path, final_proof)
        
        if lean_result.success:
            self.stats['lean_validated'] += 1
        
        # 5. Crear resoluci√≥n
        resolution = PhoenixResolution(
            theorem_context=context,
            mathematical_truth=None,  # TODO: Extract from enriched_context
            proposed_proof=initial_proof,
            lean_validated=lean_result.success,
            qcal_coherent=True,  # Will be verified by vault
            iterations=iterations,
            final_proof=final_proof,
            timestamp=datetime.now().isoformat()
        )
        
        return resolution
    
    def _finalize(self) -> Dict:
        """Finaliza y genera reporte"""
        self.stats['end_time'] = time.time()
        duration = self.stats['end_time'] - self.stats['start_time']
        
        results = {
            'stats': {
                **self.stats,
                'duration_seconds': duration,
                'success_rate': (self.stats['sorrys_resolved'] / self.stats['sorrys_scanned'] * 100
                               if self.stats['sorrys_scanned'] > 0 else 0)
            },
            'resolutions': [
                {
                    'theorem': r.theorem_context.theorem_name,
                    'file': str(r.theorem_context.file_path),
                    'iterations': r.iterations,
                    'lean_validated': r.lean_validated,
                    'qcal_coherent': r.qcal_coherent
                }
                for r in self.resolutions
            ]
        }
        
        self._print_summary()
        return results
    
    def _print_summary(self):
        """Imprime resumen final"""
        print("\n" + "=" * 80)
        print("üìä PHOENIX SOLVER SUMMARY")
        print("=" * 80)
        print(f"Sorry statements scanned: {self.stats['sorrys_scanned']}")
        print(f"Sorry statements resolved: {self.stats['sorrys_resolved']}")
        print(f"Lean validated proofs: {self.stats['lean_validated']}")
        print(f"Total iterations: {self.stats['iterations_total']}")
        print(f"Coherence checks: {self.stats['coherence_checks']}")
        print(f"Rollbacks: {self.stats['rollbacks']}")
        
        if self.stats['sorrys_scanned'] > 0:
            success_rate = self.stats['sorrys_resolved'] / self.stats['sorrys_scanned'] * 100
            print(f"\nSuccess rate: {success_rate:.1f}%")
        
        duration = self.stats['end_time'] - self.stats['start_time']
        print(f"Duration: {duration:.2f} seconds")
        print("=" * 80)
        
        if self.stats['sorrys_resolved'] == self.stats['sorrys_scanned'] and self.stats['rollbacks'] == 0:
            print("\nüèÜ QED ABSOLUTUM - All sorry statements resolved!")
            print("‚à¥ Riemann Hypothesis: FORMALLY VERIFIED")
            print("‚à¥ QCAL ‚àû¬≥ Coherence: MAINTAINED")


def main():
    """Entry point"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Phoenix Solver - Bucle de Resoluci√≥n No√©tica',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('--dir', type=Path, required=True,
                       help='Directory containing Lean files')
    parser.add_argument('--priority', type=str,
                       help='Priority file (e.g., RIGOROUS_UNIQUENESS_EXACT_LAW.lean)')
    parser.add_argument('--output', type=Path,
                       help='Output JSON report file')
    parser.add_argument('--dry-run', action='store_true', default=True,
                       help='Dry run mode (default: True)')
    parser.add_argument('--no-dry-run', action='store_true',
                       help='Live mode (disable dry-run)')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='Verbose output')
    
    args = parser.parse_args()
    
    dry_run = args.dry_run and not args.no_dry_run
    base_dir = Path.cwd()
    
    solver = PhoenixSolver(base_dir, verbose=args.verbose, dry_run=dry_run)
    results = solver.solve(args.dir, args.priority)
    
    if args.output:
        with open(args.output, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        print(f"\nüìÑ Report saved to: {args.output}")
    
    return 0 if results['stats']['rollbacks'] == 0 else 1


if __name__ == '__main__':
    sys.exit(main())
